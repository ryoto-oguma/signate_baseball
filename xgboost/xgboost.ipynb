{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os,sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:\\\\Users\\\\oguma\\\\Desktop\\\\山下研究室\\\\signate\\\\広島カープ\\\\球種部門\\\\特徴量エンジニアリング\\\\data\\\\merge.csv')\n",
    "train = train.iloc[:,1:]\n",
    "\n",
    "label = pd.read_csv('C:\\\\Users\\\\oguma\\\\Desktop\\\\山下研究室\\\\signate\\\\広島カープ\\\\球種部門\\\\特徴量エンジニアリング\\\\data\\\\label.csv')\n",
    "label = label.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_2 = []\n",
    "l = label['球種'].tolist()\n",
    "for i in range(len(l)):\n",
    "    if l[i] != 0:\n",
    "        label_2.append(1)\n",
    "    else:\n",
    "        label_2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_2 = pd.DataFrame(label_2)\n",
    "label_2.columns = ['球種']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Counter({0: 120396, 1: 136721})"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "collections.Counter(label_2['球種'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.iloc[:,:20000]\n",
    "#label = label.iloc[:,:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ構成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train,label = label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ハイパーパラメータ\n",
    "params = {'objective':'multi:softprob','num_class':8,'eta':0.3,'max_depth':12}\n",
    "num_round = 200\n",
    "#試行回数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0]\ttrain-mlogloss:1.86615+0.0018735\ttest-mlogloss:1.88725+0.000876\n[1]\ttrain-mlogloss:1.75221+0.001933\ttest-mlogloss:1.78851+0.0019335\n[2]\ttrain-mlogloss:1.67846+0.00385\ttest-mlogloss:1.72808+0.0021565\n[3]\ttrain-mlogloss:1.62533+0.0049245\ttest-mlogloss:1.68794+0.002723\n[4]\ttrain-mlogloss:1.58716+0.004518\ttest-mlogloss:1.66045+0.0030475\n[5]\ttrain-mlogloss:1.55713+0.006831\ttest-mlogloss:1.64123+0.003034\n[6]\ttrain-mlogloss:1.53422+0.0077755\ttest-mlogloss:1.62765+0.003272\n[7]\ttrain-mlogloss:1.51402+0.0059\ttest-mlogloss:1.61742+0.004253\n[8]\ttrain-mlogloss:1.49623+0.008964\ttest-mlogloss:1.60977+0.0037895\n[9]\ttrain-mlogloss:1.48095+0.011167\ttest-mlogloss:1.60394+0.003715\n[10]\ttrain-mlogloss:1.469+0.01015\ttest-mlogloss:1.59974+0.0040205\n[11]\ttrain-mlogloss:1.45842+0.0099555\ttest-mlogloss:1.59622+0.0041555\n[12]\ttrain-mlogloss:1.4481+0.00764\ttest-mlogloss:1.59308+0.004702\n[13]\ttrain-mlogloss:1.43927+0.0097775\ttest-mlogloss:1.59063+0.004163\n[14]\ttrain-mlogloss:1.42989+0.009712\ttest-mlogloss:1.58871+0.0044155\n[15]\ttrain-mlogloss:1.42063+0.011424\ttest-mlogloss:1.5865+0.003757\n[16]\ttrain-mlogloss:1.41549+0.0111365\ttest-mlogloss:1.58549+0.0038185\n[17]\ttrain-mlogloss:1.40881+0.011603\ttest-mlogloss:1.58454+0.0036435\n[18]\ttrain-mlogloss:1.40073+0.0140415\ttest-mlogloss:1.58323+0.003525\n[19]\ttrain-mlogloss:1.39497+0.013762\ttest-mlogloss:1.58222+0.0036995\n[20]\ttrain-mlogloss:1.38738+0.0122955\ttest-mlogloss:1.58139+0.003405\n[21]\ttrain-mlogloss:1.38071+0.012277\ttest-mlogloss:1.58046+0.003357\n[22]\ttrain-mlogloss:1.37615+0.0126395\ttest-mlogloss:1.57993+0.003331\n[23]\ttrain-mlogloss:1.36855+0.01453\ttest-mlogloss:1.57931+0.002947\n[24]\ttrain-mlogloss:1.36401+0.015042\ttest-mlogloss:1.57904+0.002896\n[25]\ttrain-mlogloss:1.35885+0.014113\ttest-mlogloss:1.5786+0.0029645\n[26]\ttrain-mlogloss:1.35276+0.0134095\ttest-mlogloss:1.57808+0.0029175\n[27]\ttrain-mlogloss:1.34821+0.0125525\ttest-mlogloss:1.57791+0.0030545\n[28]\ttrain-mlogloss:1.34348+0.0134955\ttest-mlogloss:1.57736+0.0027235\n[29]\ttrain-mlogloss:1.3367+0.0125435\ttest-mlogloss:1.57725+0.0027335\n[30]\ttrain-mlogloss:1.33217+0.0117505\ttest-mlogloss:1.57683+0.002922\n[31]\ttrain-mlogloss:1.3268+0.010962\ttest-mlogloss:1.57656+0.0029535\n[32]\ttrain-mlogloss:1.32103+0.0121905\ttest-mlogloss:1.57617+0.002711\n[33]\ttrain-mlogloss:1.31707+0.0110545\ttest-mlogloss:1.57614+0.0027905\n[34]\ttrain-mlogloss:1.31293+0.0113215\ttest-mlogloss:1.57593+0.0029435\n[35]\ttrain-mlogloss:1.30788+0.0109855\ttest-mlogloss:1.5756+0.0031985\n[36]\ttrain-mlogloss:1.30261+0.0119195\ttest-mlogloss:1.5752+0.0029775\n[37]\ttrain-mlogloss:1.29553+0.010699\ttest-mlogloss:1.57488+0.0030975\n[38]\ttrain-mlogloss:1.29123+0.0110135\ttest-mlogloss:1.57486+0.0030815\n[39]\ttrain-mlogloss:1.28672+0.0118595\ttest-mlogloss:1.57469+0.003019\n[40]\ttrain-mlogloss:1.28281+0.0109005\ttest-mlogloss:1.57462+0.003131\n[41]\ttrain-mlogloss:1.27667+0.0103425\ttest-mlogloss:1.57425+0.003195\n[42]\ttrain-mlogloss:1.27199+0.01007\ttest-mlogloss:1.57423+0.003181\n[43]\ttrain-mlogloss:1.26625+0.0090375\ttest-mlogloss:1.57394+0.0033595\n[44]\ttrain-mlogloss:1.26123+0.009073\ttest-mlogloss:1.57384+0.0034\n[45]\ttrain-mlogloss:1.25644+0.0092815\ttest-mlogloss:1.57342+0.0031735\n[46]\ttrain-mlogloss:1.25215+0.0095255\ttest-mlogloss:1.57349+0.0031625\n[47]\ttrain-mlogloss:1.24692+0.0097805\ttest-mlogloss:1.57349+0.003104\n[48]\ttrain-mlogloss:1.24254+0.010349\ttest-mlogloss:1.5732+0.003051\n[49]\ttrain-mlogloss:1.23826+0.0093585\ttest-mlogloss:1.57313+0.003109\n[50]\ttrain-mlogloss:1.23179+0.007421\ttest-mlogloss:1.57311+0.0033035\n[51]\ttrain-mlogloss:1.22666+0.0074215\ttest-mlogloss:1.57305+0.003279\n[52]\ttrain-mlogloss:1.22223+0.0059345\ttest-mlogloss:1.57317+0.0031575\n[53]\ttrain-mlogloss:1.21928+0.0053395\ttest-mlogloss:1.57308+0.003377\n"
    }
   ],
   "source": [
    "xgb.cv(params,dtrain,num_round,nfold = 2,verbose_eval=True,early_stopping_rounds=10,metrics = ('mlogloss'),seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     train-mlogloss-mean  train-mlogloss-std  test-mlogloss-mean  \\\n0               1.882491            0.000835            1.887331   \n1               1.780773            0.001460            1.789646   \n2               1.716974            0.001748            1.729721   \n3               1.673517            0.001803            1.690055   \n4               1.642982            0.001779            1.663093   \n5               1.620295            0.002097            1.644099   \n6               1.603182            0.001945            1.630468   \n7               1.589828            0.002142            1.620478   \n8               1.579168            0.002237            1.612975   \n9               1.569791            0.001888            1.606922   \n10              1.562617            0.001412            1.602551   \n11              1.555714            0.001161            1.598680   \n12              1.549296            0.000884            1.595314   \n13              1.543572            0.001433            1.592823   \n14              1.537769            0.001719            1.590391   \n15              1.532508            0.001054            1.588222   \n16              1.527678            0.001055            1.586413   \n17              1.522677            0.001640            1.584734   \n18              1.518487            0.002140            1.583470   \n19              1.514568            0.001780            1.582293   \n20              1.509871            0.002079            1.580793   \n21              1.505959            0.002740            1.579622   \n22              1.502536            0.002812            1.578849   \n23              1.498809            0.003265            1.577819   \n24              1.494591            0.003198            1.576638   \n25              1.490810            0.002916            1.575653   \n26              1.486459            0.003544            1.574506   \n27              1.482599            0.003519            1.573462   \n28              1.478879            0.003010            1.572802   \n29              1.474860            0.002717            1.571869   \n..                   ...                 ...                 ...   \n111             1.227983            0.003062            1.541938   \n112             1.225121            0.002941            1.541853   \n113             1.222297            0.002988            1.541689   \n114             1.220016            0.002852            1.541602   \n115             1.217661            0.002925            1.541575   \n116             1.214930            0.002933            1.541435   \n117             1.212580            0.002880            1.541303   \n118             1.209935            0.002893            1.541293   \n119             1.207468            0.003002            1.541323   \n120             1.204970            0.002607            1.541195   \n121             1.202307            0.002527            1.541142   \n122             1.199582            0.002400            1.541131   \n123             1.197255            0.002311            1.541031   \n124             1.194757            0.002657            1.540973   \n125             1.192245            0.002717            1.540882   \n126             1.189564            0.002418            1.540771   \n127             1.187274            0.002244            1.540727   \n128             1.184870            0.002183            1.540541   \n129             1.182838            0.002438            1.540620   \n130             1.180603            0.002512            1.540602   \n131             1.177804            0.002489            1.540580   \n132             1.175360            0.002427            1.540605   \n133             1.173158            0.002242            1.540532   \n134             1.170671            0.002060            1.540539   \n135             1.168359            0.002144            1.540471   \n136             1.165614            0.002115            1.540360   \n137             1.163179            0.002074            1.540357   \n138             1.160876            0.002074            1.540259   \n139             1.158566            0.001813            1.540246   \n140             1.155961            0.001794            1.540219   \n\n     test-mlogloss-std  \n0             0.001529  \n1             0.002348  \n2             0.003069  \n3             0.003662  \n4             0.004091  \n5             0.004300  \n6             0.004715  \n7             0.004832  \n8             0.005009  \n9             0.005260  \n10            0.005418  \n11            0.005990  \n12            0.005834  \n13            0.006113  \n14            0.006469  \n15            0.006285  \n16            0.006358  \n17            0.006645  \n18            0.006787  \n19            0.006464  \n20            0.006590  \n21            0.006611  \n22            0.006514  \n23            0.006500  \n24            0.006542  \n25            0.006406  \n26            0.006744  \n27            0.006542  \n28            0.006491  \n29            0.006477  \n..                 ...  \n111           0.006291  \n112           0.006259  \n113           0.006269  \n114           0.006226  \n115           0.006243  \n116           0.006235  \n117           0.006289  \n118           0.006330  \n119           0.006335  \n120           0.006400  \n121           0.006419  \n122           0.006423  \n123           0.006393  \n124           0.006518  \n125           0.006497  \n126           0.006399  \n127           0.006386  \n128           0.006354  \n129           0.006333  \n130           0.006298  \n131           0.006384  \n132           0.006410  \n133           0.006268  \n134           0.006211  \n135           0.006235  \n136           0.006256  \n137           0.006230  \n138           0.006226  \n139           0.006119  \n140           0.006083  \n\n[141 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train-mlogloss-mean</th>\n      <th>train-mlogloss-std</th>\n      <th>test-mlogloss-mean</th>\n      <th>test-mlogloss-std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.882491</td>\n      <td>0.000835</td>\n      <td>1.887331</td>\n      <td>0.001529</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.780773</td>\n      <td>0.001460</td>\n      <td>1.789646</td>\n      <td>0.002348</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.716974</td>\n      <td>0.001748</td>\n      <td>1.729721</td>\n      <td>0.003069</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.673517</td>\n      <td>0.001803</td>\n      <td>1.690055</td>\n      <td>0.003662</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.642982</td>\n      <td>0.001779</td>\n      <td>1.663093</td>\n      <td>0.004091</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.620295</td>\n      <td>0.002097</td>\n      <td>1.644099</td>\n      <td>0.004300</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.603182</td>\n      <td>0.001945</td>\n      <td>1.630468</td>\n      <td>0.004715</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.589828</td>\n      <td>0.002142</td>\n      <td>1.620478</td>\n      <td>0.004832</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.579168</td>\n      <td>0.002237</td>\n      <td>1.612975</td>\n      <td>0.005009</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.569791</td>\n      <td>0.001888</td>\n      <td>1.606922</td>\n      <td>0.005260</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.562617</td>\n      <td>0.001412</td>\n      <td>1.602551</td>\n      <td>0.005418</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.555714</td>\n      <td>0.001161</td>\n      <td>1.598680</td>\n      <td>0.005990</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.549296</td>\n      <td>0.000884</td>\n      <td>1.595314</td>\n      <td>0.005834</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.543572</td>\n      <td>0.001433</td>\n      <td>1.592823</td>\n      <td>0.006113</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.537769</td>\n      <td>0.001719</td>\n      <td>1.590391</td>\n      <td>0.006469</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.532508</td>\n      <td>0.001054</td>\n      <td>1.588222</td>\n      <td>0.006285</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1.527678</td>\n      <td>0.001055</td>\n      <td>1.586413</td>\n      <td>0.006358</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.522677</td>\n      <td>0.001640</td>\n      <td>1.584734</td>\n      <td>0.006645</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.518487</td>\n      <td>0.002140</td>\n      <td>1.583470</td>\n      <td>0.006787</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1.514568</td>\n      <td>0.001780</td>\n      <td>1.582293</td>\n      <td>0.006464</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1.509871</td>\n      <td>0.002079</td>\n      <td>1.580793</td>\n      <td>0.006590</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1.505959</td>\n      <td>0.002740</td>\n      <td>1.579622</td>\n      <td>0.006611</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1.502536</td>\n      <td>0.002812</td>\n      <td>1.578849</td>\n      <td>0.006514</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1.498809</td>\n      <td>0.003265</td>\n      <td>1.577819</td>\n      <td>0.006500</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1.494591</td>\n      <td>0.003198</td>\n      <td>1.576638</td>\n      <td>0.006542</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1.490810</td>\n      <td>0.002916</td>\n      <td>1.575653</td>\n      <td>0.006406</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1.486459</td>\n      <td>0.003544</td>\n      <td>1.574506</td>\n      <td>0.006744</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1.482599</td>\n      <td>0.003519</td>\n      <td>1.573462</td>\n      <td>0.006542</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1.478879</td>\n      <td>0.003010</td>\n      <td>1.572802</td>\n      <td>0.006491</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1.474860</td>\n      <td>0.002717</td>\n      <td>1.571869</td>\n      <td>0.006477</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>1.227983</td>\n      <td>0.003062</td>\n      <td>1.541938</td>\n      <td>0.006291</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>1.225121</td>\n      <td>0.002941</td>\n      <td>1.541853</td>\n      <td>0.006259</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>1.222297</td>\n      <td>0.002988</td>\n      <td>1.541689</td>\n      <td>0.006269</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>1.220016</td>\n      <td>0.002852</td>\n      <td>1.541602</td>\n      <td>0.006226</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>1.217661</td>\n      <td>0.002925</td>\n      <td>1.541575</td>\n      <td>0.006243</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>1.214930</td>\n      <td>0.002933</td>\n      <td>1.541435</td>\n      <td>0.006235</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>1.212580</td>\n      <td>0.002880</td>\n      <td>1.541303</td>\n      <td>0.006289</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>1.209935</td>\n      <td>0.002893</td>\n      <td>1.541293</td>\n      <td>0.006330</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>1.207468</td>\n      <td>0.003002</td>\n      <td>1.541323</td>\n      <td>0.006335</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>1.204970</td>\n      <td>0.002607</td>\n      <td>1.541195</td>\n      <td>0.006400</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>1.202307</td>\n      <td>0.002527</td>\n      <td>1.541142</td>\n      <td>0.006419</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>1.199582</td>\n      <td>0.002400</td>\n      <td>1.541131</td>\n      <td>0.006423</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>1.197255</td>\n      <td>0.002311</td>\n      <td>1.541031</td>\n      <td>0.006393</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>1.194757</td>\n      <td>0.002657</td>\n      <td>1.540973</td>\n      <td>0.006518</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>1.192245</td>\n      <td>0.002717</td>\n      <td>1.540882</td>\n      <td>0.006497</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>1.189564</td>\n      <td>0.002418</td>\n      <td>1.540771</td>\n      <td>0.006399</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>1.187274</td>\n      <td>0.002244</td>\n      <td>1.540727</td>\n      <td>0.006386</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>1.184870</td>\n      <td>0.002183</td>\n      <td>1.540541</td>\n      <td>0.006354</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>1.182838</td>\n      <td>0.002438</td>\n      <td>1.540620</td>\n      <td>0.006333</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>1.180603</td>\n      <td>0.002512</td>\n      <td>1.540602</td>\n      <td>0.006298</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>1.177804</td>\n      <td>0.002489</td>\n      <td>1.540580</td>\n      <td>0.006384</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>1.175360</td>\n      <td>0.002427</td>\n      <td>1.540605</td>\n      <td>0.006410</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>1.173158</td>\n      <td>0.002242</td>\n      <td>1.540532</td>\n      <td>0.006268</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>1.170671</td>\n      <td>0.002060</td>\n      <td>1.540539</td>\n      <td>0.006211</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>1.168359</td>\n      <td>0.002144</td>\n      <td>1.540471</td>\n      <td>0.006235</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>1.165614</td>\n      <td>0.002115</td>\n      <td>1.540360</td>\n      <td>0.006256</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>1.163179</td>\n      <td>0.002074</td>\n      <td>1.540357</td>\n      <td>0.006230</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>1.160876</td>\n      <td>0.002074</td>\n      <td>1.540259</td>\n      <td>0.006226</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>1.158566</td>\n      <td>0.001813</td>\n      <td>1.540246</td>\n      <td>0.006119</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>1.155961</td>\n      <td>0.001794</td>\n      <td>1.540219</td>\n      <td>0.006083</td>\n    </tr>\n  </tbody>\n</table>\n<p>141 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594606078315",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}